import torchfrom transformers import BertForSequenceClassification, BertTokenizerclass BERTTextClassifier:    def __init__(self, model_name):        self.tokenizer = BertTokenizer.from_pretrained(model_name)        self.classifier = BertForSequenceClassification.from_pretrained(model_name).eval()            def preprocessing(self, text):        return ' '.join(text.lower().split())        def __call__(self, text):        inp_ids = self.tokenizer.encode_plus(            self.preprocessing(text.lower()),            add_special_tokens=True,            max_length=64,            return_token_type_ids=False,            padding='max_length',            truncation=True,            return_attention_mask=True,            return_tensors='pt',        )        with torch.no_grad():            return self.classifier(**inp_ids).logits[0].argmax().item() == 1